{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MLP&CNN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNrGqARCr4G/qpjzTnU8Uxe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"XL7g1QjLuJTR","executionInfo":{"status":"ok","timestamp":1606793204912,"user_tz":-540,"elapsed":749,"user":{"displayName":"Daye Kang","photoUrl":"","userId":"01681206540751030619"}}},"source":["batch_size = 100\n","learning_rate = 0.001\n","training_epochs = 15"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"Am4UT5TPqKCU","executionInfo":{"status":"ok","timestamp":1606793206150,"user_tz":-540,"elapsed":697,"user":{"displayName":"Daye Kang","photoUrl":"","userId":"01681206540751030619"}}},"source":["import torch\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","import torch.nn.init"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"gGnUSVgNr2IZ","executionInfo":{"status":"ok","timestamp":1606793207329,"user_tz":-540,"elapsed":670,"user":{"displayName":"Daye Kang","photoUrl":"","userId":"01681206540751030619"}}},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'     # 처리속도 향상을 위해 그래픽카드 사용하는 구문. 그래픽 카드가 없으면 'cpu' 사용 / 많이 쓰는 구문"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"uiqvv4Y8rPge","executionInfo":{"status":"ok","timestamp":1606793208521,"user_tz":-540,"elapsed":465,"user":{"displayName":"Daye Kang","photoUrl":"","userId":"01681206540751030619"}}},"source":["# dataset\n","mnist_train = dsets.MNIST(root='MNIST_data/', train=True,\n","                          transform = transforms.ToTensor(), download=True)    # 훈련집합(tensor, 4차원 배열로 변환)\n","mnist_test = dsets.MNIST(root='MNIST_data/', train=False,\n","                          transform = transforms.ToTensor(), download=True)    # 테스트집합\n","                          "],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"id":"MsHvmmIwsHqx","executionInfo":{"status":"ok","timestamp":1606793210701,"user_tz":-540,"elapsed":685,"user":{"displayName":"Daye Kang","photoUrl":"","userId":"01681206540751030619"}},"outputId":"07938db4-208e-42c3-c797-741ee704a337"},"source":["import matplotlib.pyplot as plt\n","plt.imshow(mnist_train[10][0].numpy().reshape(28,28), cmap='gray')     # tensor를 2차원 행렬로 변환 / 첫번째 []는 데이터 인덱스, 두번째 []는 레이블 유무(0 = 시각화 / 1 = 데이터 값(레이블))\n","print(mnist_train[10][1])       # 두번째 []가 1이므로 데이터 값 출력\n","plt.show()"],"execution_count":44,"outputs":[{"output_type":"stream","text":["3\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANcElEQVR4nO3df6gd9ZnH8c9ntVE0kSSK8WL9kUZFg2KyRlFWF9eSkhUlFqQ2yOKyws0fVaoI2VDBCJuC7hpXglhIUZtduimFGCql0rghrOs/JVGzGhPbZENic40J7kVr/Scan/3jTuSq98y5OTNz5uQ+7xdczjnznJl5OOSTmTM/ztcRIQBT31+03QCA/iDsQBKEHUiCsANJEHYgiVP7uTLbHPoHGhYRnmh6pS277SW2f297r+2VVZYFoFnu9Ty77VMk/UHSYkkHJW2TtCwidpXMw5YdaFgTW/brJO2NiH0RcVTSLyQtrbA8AA2qEvbzJf1x3OuDxbQvsT1se7vt7RXWBaCixg/QRcQ6SeskduOBNlXZso9IumDc628W0wAMoCph3ybpUttzbU+T9H1JL9bTFoC69bwbHxGf2b5P0m8lnSLpuYh4u7bOANSq51NvPa2M7+xA4xq5qAbAyYOwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgST6OmQzmjF//vyOtdtuu6103uHh4dL6tm3bSutvvPFGab3MU089VVo/evRoz8vG17FlB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGMX1JLB8+fLS+hNPPNGxNn369Lrbqc0tt9xSWt+6dWufOplaOo3iWumiGtv7JX0s6ZikzyJiUZXlAWhOHVfQ/U1EfFDDcgA0iO/sQBJVwx6SNtt+zfaEF1nbHra93fb2iusCUEHV3fgbI2LE9rmSXrb9TkS8Mv4NEbFO0jqJA3RAmypt2SNipHg8ImmTpOvqaApA/XoOu+0zbc84/lzSdyTtrKsxAPXq+Ty77W9pbGsujX0d+I+I+HGXediN78Hs2bNL67t37+5YO/fcc+tupzYffvhhaf2uu+4qrW/evLnOdqaM2s+zR8Q+SVf33BGAvuLUG5AEYQeSIOxAEoQdSIKwA0nwU9IngdHR0dL6qlWrOtbWrFlTOu8ZZ5xRWn/33XdL6xdeeGFpvczMmTNL60uWLCmtc+rtxLBlB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk+CnpKW7Hjh2l9auvLr9xcefO8p8ouPLKK0+4p8maN29eaX3fvn2Nrftk1ukWV7bsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE97NPcatXry6tP/zww6X1BQsW1NnOCZk2bVpr656K2LIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBLcz57ceeedV1rv9tvsV111VZ3tfMnGjRtL63feeWdj6z6Z9Xw/u+3nbB+xvXPctNm2X7a9p3icVWezAOo3md34n0n66tAcKyVtiYhLJW0pXgMYYF3DHhGvSPrq+ENLJa0vnq+XdEfNfQGoWa/Xxs+JiEPF8/clzen0RtvDkoZ7XA+AmlS+ESYiouzAW0Ssk7RO4gAd0KZeT70dtj0kScXjkfpaAtCEXsP+oqR7iuf3SPpVPe0AaErX3XjbGyTdLOkc2wclrZL0mKRf2r5X0gFJ32uySfTu7rvvLq13+934Jn8XvptXX321tXVPRV3DHhHLOpS+XXMvABrE5bJAEoQdSIKwA0kQdiAJwg4kwS2uJ4HLL7+8tL5p06aOtUsuuaR03lNPHdxfE2fI5t4wZDOQHGEHkiDsQBKEHUiCsANJEHYgCcIOJDG4J1nxhSuuuKK0Pnfu3I61QT6P3s2DDz5YWr///vv71MnUwJYdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5I4eU/CJlJ2v7okrVixomPt8ccfL5339NNP76mnfhgaGmq7hSmFLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMF59ilg7dq1HWt79uwpnXfmzJmV1t3tfvmnn366Y+2ss86qtG6cmK5bdtvP2T5ie+e4aY/aHrG9o/i7tdk2AVQ1md34n0laMsH0f42IBcXfb+ptC0DduoY9Il6RNNqHXgA0qMoBuvtsv1ns5s/q9Cbbw7a3295eYV0AKuo17D+RNE/SAkmHJK3p9MaIWBcRiyJiUY/rAlCDnsIeEYcj4lhEfC7pp5Kuq7ctAHXrKey2x997+F1JOzu9F8Bg6Hqe3fYGSTdLOsf2QUmrJN1se4GkkLRf0vIGe0QFL730UqPLtyccCvwLZePDP/LII6XzLliwoLR+0UUXldYPHDhQWs+ma9gjYtkEk59toBcADeJyWSAJwg4kQdiBJAg7kARhB5LgFldUMm3atNJ6t9NrZT799NPS+rFjx3pedkZs2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCc6zo5LVq1c3tuxnny2/ufLgwYONrXsqYssOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0k4Ivq3Mrt/K6vZ2Wef3bH2/PPPl867YcOGSvU2DQ0Nldbfeeed0nqVYZnnzZtXWt+3b1/Py57KImLC3/dmyw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSXA/+yStXbu2Y+32228vnfeyyy4rrb/33nul9ZGRkdL63r17O9auueaa0nm79bZixYrSepXz6GvWrCmtd/tccGK6btltX2B7q+1dtt+2/cNi+mzbL9veUzzOar5dAL2azG78Z5Ieioj5kq6X9APb8yWtlLQlIi6VtKV4DWBAdQ17RByKiNeL5x9L2i3pfElLJa0v3rZe0h1NNQmguhP6zm77YkkLJf1O0pyIOFSU3pc0p8M8w5KGe28RQB0mfTTe9nRJGyU9EBF/Gl+LsbtpJrzJJSLWRcSiiFhUqVMAlUwq7La/obGg/zwiXigmH7Y9VNSHJB1ppkUAdeh6i6tta+w7+WhEPDBu+r9I+r+IeMz2SkmzI6L0PM3JfIvr9ddf37H25JNPls57ww03VFr3/v37S+u7du3qWLvppptK550xY0YvLX2h27+fsltgr7322tJ5P/nkk556yq7TLa6T+c7+V5L+TtJbtncU034k6TFJv7R9r6QDkr5XR6MAmtE17BHxqqQJ/6eQ9O162wHQFC6XBZIg7EAShB1IgrADSRB2IAl+SroG3W7VLLsFVZKeeeaZOtvpq9HR0dJ62U9woxn8lDSQHGEHkiDsQBKEHUiCsANJEHYgCcIOJMFPSdfgoYceKq2fdtpppfXp06dXWv/ChQs71pYtW1Zp2R999FFpffHixZWWj/5hyw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSXA/OzDFcD87kBxhB5Ig7EAShB1IgrADSRB2IAnCDiTRNey2L7C91fYu22/b/mEx/VHbI7Z3FH+3Nt8ugF51vajG9pCkoYh43fYMSa9JukNj47H/OSKemPTKuKgGaFyni2omMz77IUmHiucf294t6fx62wPQtBP6zm77YkkLJf2umHSf7TdtP2d7Vod5hm1vt729UqcAKpn0tfG2p0v6L0k/jogXbM+R9IGkkPRPGtvV/4cuy2A3HmhYp934SYXd9jck/VrSbyPiyQnqF0v6dURc2WU5hB1oWM83wti2pGcl7R4f9OLA3XHflbSzapMAmjOZo/E3SvpvSW9J+ryY/CNJyyQt0Nhu/H5Jy4uDeWXLYssONKzSbnxdCDvQPO5nB5Ij7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJNH1Bydr9oGkA+Nen1NMG0SD2tug9iXRW6/q7O2iToW+3s/+tZXb2yNiUWsNlBjU3ga1L4neetWv3tiNB5Ig7EASbYd9XcvrLzOovQ1qXxK99aovvbX6nR1A/7S9ZQfQJ4QdSKKVsNteYvv3tvfaXtlGD53Y3m/7rWIY6lbHpyvG0Dtie+e4abNtv2x7T/E44Rh7LfU2EMN4lwwz3upn1/bw533/zm77FEl/kLRY0kFJ2yQti4hdfW2kA9v7JS2KiNYvwLD915L+LOnfjg+tZfufJY1GxGPFf5SzIuIfB6S3R3WCw3g31FunYcb/Xi1+dnUOf96LNrbs10naGxH7IuKopF9IWtpCHwMvIl6RNPqVyUslrS+er9fYP5a+69DbQIiIQxHxevH8Y0nHhxlv9bMr6asv2gj7+ZL+OO71QQ3WeO8habPt12wPt93MBOaMG2brfUlz2mxmAl2H8e6nrwwzPjCfXS/Dn1fFAbqvuzEi/lLS30r6QbG7OpBi7DvYIJ07/YmkeRobA/CQpDVtNlMMM75R0gMR8afxtTY/uwn66svn1kbYRyRdMO71N4tpAyEiRorHI5I2aexrxyA5fHwE3eLxSMv9fCEiDkfEsYj4XNJP1eJnVwwzvlHSzyPihWJy65/dRH3163NrI+zbJF1qe67taZK+L+nFFvr4GttnFgdOZPtMSd/R4A1F/aKke4rn90j6VYu9fMmgDOPdaZhxtfzZtT78eUT0/U/SrRo7Iv+/kh5uo4cOfX1L0v8Uf2+33ZukDRrbrftUY8c27pV0tqQtkvZI+k9Jsweot3/X2NDeb2osWEMt9XajxnbR35S0o/i7te3PrqSvvnxuXC4LJMEBOiAJwg4kQdiBJAg7kARhB5Ig7EAShB1I4v8BbAEsnwu8EY8AAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"XhIjfxBts62f","executionInfo":{"status":"ok","timestamp":1606793214481,"user_tz":-540,"elapsed":760,"user":{"displayName":"Daye Kang","photoUrl":"","userId":"01681206540751030619"}}},"source":[" # 학습용 데이터 \n","data_loader = torch.utils.data.DataLoader(dataset=mnist_train,                  # mnist_train을 학습데이터로 사용\n","                                          batch_size = batch_size,\n","                                          shuffle=True,\n","                                          drop_last=True)"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"YkJKu03OuIK6","executionInfo":{"status":"ok","timestamp":1606793215743,"user_tz":-540,"elapsed":652,"user":{"displayName":"Daye Kang","photoUrl":"","userId":"01681206540751030619"}}},"source":["# fully connected 클래스 생성(MLP)\n","\n","class FC(torch.nn.Module):                                     # 해당 모듈에서 불러 사용 가능(해당 모듈 객체를 상속)\n","    def __init__(self):                                        # 추가적으로 사용할 속성만 선언\n","      super(FC,self).__init__()                                # 여러가지의 속성이 있는데 super 함수를 사용하면 앞에서 만들어 놓은 것들을 그대로 상속 받아 사용 가능\n","      self.layer1 = torch.nn.Sequential(                       # sequential : 차례차례 순차적으로 처리\n","          torch.nn.Linear(28*28, 100, bias=True),              # hidden node 100개, bias node = True\n","          torch.nn.ReLU()                                      # ReLU 활성함수(분류, classification) 지정\n","      )\n","      self.layer2 = torch.nn.Linear(100, 10)                   # hidden node 100개 / output(class 0-9) 10개\n","      torch.nn.init.xavier_uniform_(self.layer2.weight)        # 2번째 레이어(output)의 weight 초기화() / FC에서 많이 사용 / __init__(self):함수 안에서 구현이 되는데 처음에 클래스를 만들 때 동작하고 이후에는 동작하지 않음 ==> 처음에만 초기화\n","\n","    def forward(self,x):                                       # forward method 정의(순방향 계산)\n","      x2 = x.view(x.size(0), -1)                               # input으로 들어온 28*28 샘플을 각각 열행렬로 변환 ==> 784*1 행렬\n","      out = self.layer1(x2)                                    # layer1의 param으로 x2\n","      out = self.layer2(out)                                   # layer2의 param으로 layer1의 값(100개의 히든노드를 거쳐 나온 활성값)을 out에 대입\n","      return out                                               # out return"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"ycn9ku_obvYt","executionInfo":{"status":"ok","timestamp":1606798103041,"user_tz":-540,"elapsed":721,"user":{"displayName":"Daye Kang","photoUrl":"","userId":"01681206540751030619"}}},"source":["# CNN class 생성\n","\n","class CNN(torch.nn.Module):                                     \n","    def __init__(self):                                      \n","      super(CNN,self).__init__()                                                  # super 함수를 사용해 앞에서 만들어 놓은 것들을 그대로 상속 받아 사용 가능\n","      self.layer1 = torch.nn.Sequential(                                          # 히든 1층(컨볼루션 1층, 맥스풀링 1층)\n","          torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),             # 1장(28*28)을 32장으로\n","          torch.nn.ReLU(),                                                        # ReLU 활성함수(분류, classification) \n","          torch.nn.MaxPool2d(kernel_size=2, stride=2)                             # 맥스풀링층 추가\n","      )\n","      self.layer2 = torch.nn.Sequential(                                          # 히든 2층(컨볼루션 1층, 맥스풀링 1층)\n","          torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),            # 32장을 64장으로\n","          torch.nn.ReLU(),                                    \n","          torch.nn.MaxPool2d(kernel_size=2, stride=2)\n","      )\n","      self.fc = torch.nn.Linear(7*7*64, 10, bias=True)                            # fc층 / output(class 0-9) 10개\n","      torch.nn.init.xavier_uniform_(self.fc.weight)                               # weight 초기화() / FC에서는 이 방법으로 초기화를 많이 사용\n","\n","    def forward(self,x):                                       \n","      out = self.layer1(x)                                                        # x가 바로 layer1의 param으로 들어감(컨볼루션 층이기 때문에 변환x)\n","      out = self.layer2(out)                                                      # layer2의 param으로 layer1의 값(100개의 히든노드를 거쳐 나온 활성값)을 out에 대입\n","      out = out.view(out.size(0), -1)                                             # fc 층에 들어가기 전에 열행렬로 변환\n","      out = self.fc(out)                                                          # fc 층에 값 넣기\n","      return out                                                                  # out return / 총 5개층"],"execution_count":69,"outputs":[]},{"cell_type":"code","metadata":{"id":"DRMQpBaUzxtO","executionInfo":{"status":"ok","timestamp":1606798107667,"user_tz":-540,"elapsed":671,"user":{"displayName":"Daye Kang","photoUrl":"","userId":"01681206540751030619"}}},"source":["# instance 생성\n","# model = FC().to(device)          # 연산처리를 그래픽에서 실행할 수 있도록 설정 / FC\n","model = CNN().to(device)          # CNN"],"execution_count":70,"outputs":[]},{"cell_type":"code","metadata":{"id":"tfqxNJ4-0HlT","executionInfo":{"status":"ok","timestamp":1606798111927,"user_tz":-540,"elapsed":710,"user":{"displayName":"Daye Kang","photoUrl":"","userId":"01681206540751030619"}}},"source":["# 목적함수 설정(파라미터, 가중치 최적화를 위한 함수 / optimizer = stochastic gradient descent, batch gradient descent 등)\n","criterion = torch.nn.CrossEntropyLoss().to(device)         # Cross Entropy\n","# criterion = torch.nn.MSELoss.to(device)                  # MSE\n","# criterion = torch.nn.NLLLoss().to(device)                # 로그우도\n","\n","\n","# 가중치 최적화\n","optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)       # stochastic gradient descent 아니고 더 좋은 거"],"execution_count":71,"outputs":[]},{"cell_type":"code","metadata":{"id":"1pcr1uboWdLk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606798195364,"user_tz":-540,"elapsed":81288,"user":{"displayName":"Daye Kang","photoUrl":"","userId":"01681206540751030619"}},"outputId":"5ba375c5-232e-4775-97a4-9f02e7b48748"},"source":["# 본격적인 학습 시작(machine learning)\n","\n","# print(len(data_loader))  ==> 600개 / training set의 데이터 전체 개수는 60,000개. 이때, batch_size가 100이기 때문에 100개씩 나누면 600개의 set. \n","total_batch = len(data_loader)             # 한 epoch을 돌 때 총 batch 개수\n","\n","for epoch in range(training_epochs):\n","  avg_cost = 0                             # 손실 비용, loss function, 목적함수 값이 감소되는 것을 확인하기 위함\n","\n","  for X,Y in data_loader:\n","    X = X.to(device)\n","    Y = Y.to(device)\n","    optimizer.zero_grad()\n","    hypothesis = model(X)                  # model instance에 훈련 feature X를 넣어 out(출력값)을 hypothesis에 대입\n","    cost = criterion(hypothesis, Y)        # hypothesis와 훈련집합의 Y(label, 실제 정답)을 목적함수에 넣어 \n","    cost.backward()                        \n","    optimizer.step()                       # 모형 학습(cost.backward()와 optimizer.step() 두 과정을 모형학습이라고 할 수 있음)\n","\n","    avg_cost += cost/total_batch           # 한 단위인 batch_size(100)별로 계산된 cost를 다 합한 후(600개), total_batch로 나눠 avg_cost 계산\n","    # print(\"cost: \", cost)\n","    # print(\"avg_cost: \", len(avg_cost))\n","\n","  print(\"[Epoch: {:>4}, cost: {:>.9}]\".format(epoch+1, avg_cost))"],"execution_count":72,"outputs":[{"output_type":"stream","text":["[Epoch:    1, cost: 0.226127863]\n","[Epoch:    2, cost: 0.0612153225]\n","[Epoch:    3, cost: 0.0464232191]\n","[Epoch:    4, cost: 0.0365589708]\n","[Epoch:    5, cost: 0.0309077594]\n","[Epoch:    6, cost: 0.0254950449]\n","[Epoch:    7, cost: 0.0215110164]\n","[Epoch:    8, cost: 0.0184704587]\n","[Epoch:    9, cost: 0.0147461956]\n","[Epoch:   10, cost: 0.0129029267]\n","[Epoch:   11, cost: 0.0118002249]\n","[Epoch:   12, cost: 0.00966401398]\n","[Epoch:   13, cost: 0.00789414253]\n","[Epoch:   14, cost: 0.00736873457]\n","[Epoch:   15, cost: 0.00619690772]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"StNMWZiCFKFa","executionInfo":{"status":"ok","timestamp":1606798260581,"user_tz":-540,"elapsed":791,"user":{"displayName":"Daye Kang","photoUrl":"","userId":"01681206540751030619"}},"outputId":"3e76b4fc-0034-490b-ac50-1ec6cc605d94"},"source":["with torch.no_grad():                                                                 # gradient 없이 계산하겠다는(with를 써서), 테스트 데이터 셋으로 정확도 파악\n","    X_test = mnist_test.test_data.view(len(mnist_test),1,28,28).float().to(device)    # 10,000 * 1 * 28 * 28의 tensor로 변환\n","    Y_test = mnist_test.test_labels.to(device)                                        # 정수(값)\n","\n","    # output\n","    prediction = model(X_test)                                                        # 훈련집합 X,Y로 model의 가중치를 업데이트 했기 때문에 X_test를 넣어주기만 하면 최신 가중치의 out 값 출력 \n","    print(prediction.size())                                                          # torch.Size([10000, 10]) ==> 10,000개의 샘플들의 0-9까지의 클래스 결과(확률)이 나옴, 가장 큰 값(확률)로 분류(argmax)\n","    print(torch.argmax(prediction,1))                                                 # tensor([7, 2, 1,  ..., 4, 5, 6], device='cuda:0') ==> 10,000개의 분류된 값 출력 \n","\n","    correct_prediction = torch.argmax(prediction, 1) == Y_test                        # 답지와 비교\n","    print(correct_prediction)                                                         # type = class 'torch.Tensor' / not list\n","\n","    accuracy = correct_prediction.float().mean()                                      # 1, 0으로 변환해서 평균 계산\n","    print(\"Accuracy: \", accuracy.item())                                              # 정확도 (FC: 97.78999 / CNN: 98.4499999)\n","    # print(type(accuracy))"],"execution_count":73,"outputs":[{"output_type":"stream","text":["torch.Size([10000, 10])\n","tensor([7, 2, 1,  ..., 4, 5, 6], device='cuda:0')\n","tensor([True, True, True,  ..., True, True, True], device='cuda:0')\n","Accuracy:  0.984499990940094\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n","  warnings.warn(\"test_data has been renamed data\")\n","/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: test_labels has been renamed targets\n","  warnings.warn(\"test_labels has been renamed targets\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"QRITYKGKVZnC"},"source":[""],"execution_count":null,"outputs":[]}]}